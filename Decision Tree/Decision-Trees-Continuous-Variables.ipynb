{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,feature_ind,klasslabel=0,score=0,split=0,fidx=-1):\n",
    "        self.lchild=None\n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.feature_ind=feature_ind\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        self.lchild=lchild\n",
    "        self.rchild=rchild\n",
    "\n",
    "    def navigate(self, point):\n",
    "        if(not self.isleaf()):\n",
    "            if(point[self.feature_ind] > self.split):\n",
    "                return self.rchild.navigate(point)\n",
    "            else:\n",
    "                return self.lchild.navigate(point)\n",
    "        \n",
    "        return self.klasslabel\n",
    "            \n",
    "    def isleaf(self):\n",
    "        if self.lchild == None and self.rchild == None:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isless_than_eq(self, X):\n",
    "        if X<=fidx:\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.feature_ind)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here...\n",
    "\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=5,tree=None):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold\n",
    "        self.maxdepth=maxdepth\n",
    "        self.tree=tree\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        \n",
    "        nexamples,nfeatures=X.shape\n",
    "        self.root = self.build_tree(X, Y, self.maxdepth)\n",
    "        \n",
    "    def get_optimal_split(self, X, Y):\n",
    "        #Provide Features\n",
    "        #Returns Right and Left Child Data and Labels\n",
    "        #Returns Best Possible Split Node\n",
    "        \n",
    "        max_info_gain = -1\n",
    "        split_val = 0\n",
    "        r_child = []\n",
    "        l_child = []\n",
    "        label = -1\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "    \n",
    "        for i in range(nfeatures): #Choose Feature With Max Info Gain\n",
    "            split, info_gain, rci, lci = self.evaluate_numerical_attribute(X[:,i], Y)\n",
    "            if(info_gain > max_info_gain):\n",
    "                max_info_gain = info_gain\n",
    "                split_val = split\n",
    "                r_child = rci\n",
    "                l_child = lci\n",
    "                label = i\n",
    "        \n",
    "        R_X = X[r_child]\n",
    "        L_X = X[l_child]\n",
    "        R_Y = Y[r_child]\n",
    "        L_Y = Y[l_child]\n",
    "        \n",
    "        (values,counts) = np.unique(Y,return_counts=True)\n",
    "        ind=np.argmax(counts)\n",
    "        maj_lbl = values[ind]\n",
    "    \n",
    "        node = Node(label, maj_lbl, max_info_gain, split_val)\n",
    "\n",
    "        return node, L_X, R_X, L_Y, R_Y\n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "\n",
    "        nexamples, nfeatures=X.shape\n",
    "        klasses,C=np.unique(Y,return_counts=True);\n",
    "        \n",
    "        if(len(X) == 1):\n",
    "            node = Node(0, Y[0], 0, 0)\n",
    "            return node\n",
    "        \n",
    "        elif(len(X) == 0):\n",
    "            return None\n",
    "        \n",
    "        root, lx, rx, ly, ry = self.get_optimal_split(X, Y)\n",
    "        \n",
    "        if(depth > 0):\n",
    "            root.set_childs(self.build_tree(lx, ly, depth-1),self.build_tree(rx, ry, depth-1))\n",
    "        \n",
    "        return root\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        return pclasses\n",
    "    \n",
    "    def evaluate_numerical_attribute(self,feat, Y):\n",
    "        \n",
    "        classes=np.unique(Y)\n",
    "        nclasses=len(classes)\n",
    "\n",
    "        f = np.asarray(feat)\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        score = -99999\n",
    "        size = len(Y)\n",
    "        RCI = []\n",
    "        LCI = []\n",
    "        \n",
    "        unique, counts = np.unique(f, return_counts=True)\n",
    "        genie = 0\n",
    "        for i in counts:\n",
    "            genie += (i/size)**2\n",
    "        genie = 1.0 - genie\n",
    "        \n",
    "        i = min(f)\n",
    "        while i <= max(f):\n",
    "            leftChildInd = []\n",
    "            rightChildInd = []\n",
    "            L_Ind = []\n",
    "            R_Ind = []\n",
    "            \n",
    "            for j in range(0, len(f)):\n",
    "                if f[j] <= i:\n",
    "                    leftChildInd.append(Y[j])\n",
    "                    L_Ind.append(j)\n",
    "                else:\n",
    "                    rightChildInd.append(Y[j])\n",
    "                    R_Ind.append(j)\n",
    "                    \n",
    "            l_unique, l_counts = np.unique(leftChildInd, return_counts=True)                  \n",
    "            r_unique, r_counts = np.unique(rightChildInd, return_counts=True)\n",
    "\n",
    "            l_genie = 0\n",
    "            len_left = len(leftChildInd)\n",
    "            for x in l_counts:\n",
    "                l_genie += (x/len_left)**2\n",
    "            l_genie = 1.0-l_genie\n",
    "\n",
    "            r_genie = 0\n",
    "            len_right = len(rightChildInd)\n",
    "            for x in r_counts:\n",
    "                r_genie += (x/len_right)**2\n",
    "            r_genie = 1.0-r_genie\n",
    "\n",
    "            info_gain = genie-(((len_left/size))*l_genie)-(((len_right/size)*r_genie))\n",
    "\n",
    "            if(info_gain > score):\n",
    "                score = info_gain\n",
    "                split = i\n",
    "                RCI = np.asarray(R_Ind)\n",
    "                LCI = np.asarray(L_Ind)\n",
    "                    \n",
    "            i += 0.01\n",
    "                    \n",
    "        return split, score, RCI, LCI\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        pclass = []\n",
    "        for i in X:\n",
    "            pclass.append(self.root.navigate(i))\n",
    "\n",
    "        return pclass\n",
    "    \n",
    "    def _predict(self,node, X):\n",
    "        pass\n",
    "      \n",
    "    def __str__(self):\n",
    "        return self.__print(self.tree) \n",
    "        \n",
    "    #def find_depth(self):\n",
    "        \n",
    "        #return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "        \n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t # set of tools for plotting, data splitting, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "#print (data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (129, 4)  True Class labels dimensions (129, 1)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix (X ,Y)\n",
    "test_ind = [1,5,13,18,27,31,46,54,68,72,80,87,90,96,101,111,116,123,137,142]\n",
    "no_of_cols = len(data.columns)\n",
    "X_data = np.asarray(data)\n",
    "Y_data = X_data[:,no_of_cols-1:]\n",
    "\n",
    "X = np.delete(Xd, test_ind, axis=0)\n",
    "Y = X[:,no_of_cols-1:]\n",
    "X = X[:,:no_of_cols-1]\n",
    "\n",
    "print (\" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "Split Value:  5.409999999999976\n",
      "Information Gain:  0.5108487070087934\n"
     ]
    }
   ],
   "source": [
    "print (len(Y))\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5,2)\n",
    "feat=[0,1]\n",
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain,Xlidx,Xridx=dt.evaluate_numerical_attribute(X[:,0],Y)\n",
    "print(\"Split Value: \", split)\n",
    "print(\"Information Gain: \", mingain)\n",
    "# You should get following result:,\n",
    "# Split=5.45, entropy=0.388707191825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb\n",
    "#print (\" Plotting the Decision Surface of Training Set... \")\n",
    "#t.plot_decision_regions(X[:,feat],Y,clf=dt, res=0.1, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Data Set Dimensions= (20, 5) Test True Class labels dimensions (20, 1)\n"
     ]
    }
   ],
   "source": [
    "#*****************************Because SPLIT was not working!*****************************\n",
    "\n",
    "Xtest = X_data[test_ind]\n",
    "Ytest = Y_data[test_ind]\n",
    "\n",
    "print (\" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytest.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's See How Good we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on All 4 Features and all 3 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-setosa']  Prediction: Iris-setosa\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-versicolor']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-virginica']  Prediction: Iris-virginica\n",
      "Label: ['Iris-virginica']  Prediction: Iris-virginica\n",
      "Label: ['Iris-virginica']  Prediction: Iris-virginica\n",
      "Label: ['Iris-virginica']  Prediction: Iris-virginica\n",
      "Missclassified! :\n",
      "Label: ['Iris-virginica']  Prediction: Iris-versicolor\n",
      "Label: ['Iris-virginica']  Prediction: Iris-virginica\n",
      "\n",
      "Accuracy:  95.0 %\n"
     ]
    }
   ],
   "source": [
    "pclasses=dt.predict(Xtest)\n",
    "score = 0\n",
    "for i in range(len(pclasses)):\n",
    "    if(Ytest[i] == pclasses[i]):\n",
    "        score+=1\n",
    "    else:\n",
    "        print(\"Missclassified! :\")\n",
    "    print(\"Label:\",Ytest[i],\" Prediction:\", pclasses[i])\n",
    "score = score*100\n",
    "print()\n",
    "print(\"Accuracy: \", score/len(Ytest), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
